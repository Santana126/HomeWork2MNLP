{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e68473",
   "metadata": {},
   "source": [
    "# With Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dea379",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef98997",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers accelerate torch\n",
    "%pip install ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aeaa64",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22073a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_path = \"dataset/dataset.csv\"\n",
    "df = pd.read_csv(dataset_path) #creation of dataframe\n",
    "output_path = \"dataset/output.csv\"\n",
    "col_name = \"Sentence\"\n",
    "models = [ \"mistral\"]\n",
    "prompt_templates={\n",
    "    \"base\":        \"Traduci la seguente frase dall'italiano antico all'italiano moderno:\\n\\n{sentence}\\n\\nTraduzione:\",\n",
    "    \"piu_dettagliato\": \"Il seguente testo √® scritto in italiano arcaico del XIII secolo, proveniente dalla regione toscana. Riscrivilo in italiano moderno mantenendo il significato originale, la chiarezza e la coerenza sintattica.\\n\\n {sentence}\\n\\n\",\n",
    "    \"role-based\":   \"You are an expert linguist specializing in the evolution of Italian language. Translate this 13th century Tuscan text to contemporary Italian: \\n\\n{sentence}\\n\\n:\",\n",
    "    \"few_shot\": (\n",
    "    \"Qui ci sono alcuni esempi di frasi in italiano arcaico del XIII secolo tradotte in italiano moderno:\\n\\n\"\n",
    "    \"¬´quella guerra ben fatta l' opera perch√© etc.¬ª ‚Üí ¬´quella guerra fu condotta bene, e l'opera fu compiuta come previsto.¬ª\\n\"\n",
    "    \"¬´crudele, e di tutte le colpe pigli vendetta¬ª ‚Üí ¬´crudele, e si vendica di tutte le colpe.¬ª\\n\"\n",
    "    \"¬´Non d' altra forza d' animo fue ornato Ponzio Aufidiano¬ª ‚Üí ¬´Ponzio Aufidiano non era dotato di altro vigore d‚Äôanimo.¬ª\\n\\n\"\n",
    "    \"Ora traduci la seguente frase in italiano moderno mantenendo il significato originale:\\n\\n\"\n",
    "    \"{sentence}\\n\\nTraduzione:\"\n",
    ")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb4dde",
   "metadata": {},
   "source": [
    "## Translate the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from ollama import Client\n",
    "\n",
    "client = Client(host='http://localhost:11434')#client to local ollama\n",
    "\n",
    "for model_name in models:#iterate through models\n",
    "    for prompt_name, prompt_template in prompt_templates.items():#iterate through prompt templates\n",
    "        print(f\"\\nüîÅ Traduzione con modello: {model_name} | prompt: {prompt_name}\")\n",
    "        translations = []#list to store translations\n",
    "        for sentence in tqdm(df[col_name]):#iterate through sentences\n",
    "            try:\n",
    "                prompt = prompt_template.format(sentence=sentence)#give the prompt\n",
    "\n",
    "                response = client.chat(\n",
    "                    model=model_name,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )#ollama api call\n",
    "\n",
    "                translation = response['message']['content'].strip()#extract the translation\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                translation = f\"[ERRORE]: {e}\"\n",
    "            translations.append(translation)#append the translation to the list\n",
    "\n",
    "        df[\"translation\"] = translations# add the translations to the dataframe\n",
    "\n",
    "        output_file = f\"traduzioni_{model_name}_{prompt_name}.csv\"# create the output file name\n",
    "\n",
    "        df.to_csv(output_file, index=False)# save the dataframe to a csv file\n",
    "        print(f\"‚úÖ Traduzioni salvate in '{output_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7856f01",
   "metadata": {},
   "source": [
    "# With Hugginface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210d365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.6.0)\n",
      "Requirement already satisfied: torch in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.7.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.45.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\feder\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "üì¶ Caricamento del modello Hugging Face: tiiuae/falcon-rw-1b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff43829104254c1f9410b2b8bdde067c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   1%|          | 21.0M/2.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install transformers accelerate torch bitsandbytes\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === PERCORSI ===\n",
    "dataset_path = \"dataset/dataset.csv\"\n",
    "output_path = \"dataset/output.csv\"\n",
    "\n",
    "# === CARICAMENTO DATASET ===\n",
    "df = pd.read_csv(dataset_path) # creation of dataframe\n",
    "\n",
    "# === CONFIGURAZIONE ===\n",
    "col_name = \"Sentence\"\n",
    "models = [\"tiiuae/falcon-rw-1b\"]\n",
    "\n",
    "\n",
    "# === TEMPLATE DI PROMPT ===\n",
    "prompt_templates = {\n",
    "    \"base\":        \"Traduci la seguente frase dall'italiano antico all'italiano moderno:\\n\\n{sentence}\\n\\nTraduzione:\",\n",
    "    \"piu_dettagliato\": \"Il seguente testo √® scritto in italiano arcaico del XIII secolo, proveniente dalla regione toscana. Riscrivilo in italiano moderno mantenendo il significato originale, la chiarezza e la coerenza sintattica.\\n\\n{sentence}\\n\\nTraduzione:\",\n",
    "    \"role-based\":   \"You are an expert linguist specializing in the evolution of Italian language. Translate this 13th century Tuscan text to contemporary Italian:\\n\\n{sentence}\\n\\nTranslation:\",\n",
    "    \"few_shot\": (\n",
    "        \"Qui ci sono alcuni esempi di frasi in italiano arcaico del XIII secolo tradotte in italiano moderno:\\n\\n\"\n",
    "        \"¬´quella guerra ben fatta l' opera perch√© etc.¬ª ‚Üí ¬´quella guerra fu condotta bene, e l'opera fu compiuta come previsto.¬ª\\n\"\n",
    "        \"¬´crudele, e di tutte le colpe pigli vendetta¬ª ‚Üí ¬´crudele, e si vendica di tutte le colpe.¬ª\\n\"\n",
    "        \"¬´Non d' altra forza d' animo fue ornato Ponzio Aufidiano¬ª ‚Üí ¬´Ponzio Aufidiano non era dotato di altro vigore d‚Äôanimo.¬ª\\n\\n\"\n",
    "        \"Ora traduci la seguente frase in italiano moderno mantenendo il significato originale:\\n\\n\"\n",
    "        \"{sentence}\\n\\nTraduzione:\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# === LOOP SUI MODELLI E PROMPT ===\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "for model_name in models:  # iterate through models\n",
    "\n",
    "    print(f\"\\nüì¶ Caricamento del modello Hugging Face: {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",              # usa GPU se disponibile\n",
    "        torch_dtype=torch.float16,      # riduce consumo memoria\n",
    "    )\n",
    "\n",
    "    # === PIPELINE DI GENERAZIONE ===\n",
    "    generate = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    for prompt_name, prompt_template in prompt_templates.items():  # iterate through prompt templates\n",
    "        print(f\"\\nüîÅ Traduzione con modello: {model_name} | prompt: {prompt_name}\")\n",
    "        translations = []  # list to store translations\n",
    "\n",
    "        for sentence in tqdm(df[col_name]):  # iterate through sentences\n",
    "            try:\n",
    "                prompt = prompt_template.format(sentence=sentence)  # give the prompt\n",
    "\n",
    "                response = generate(\n",
    "                    prompt,\n",
    "                    max_new_tokens=150,\n",
    "                    do_sample=False,\n",
    "                    temperature=0.7\n",
    "                )  # Hugging Face generation call\n",
    "\n",
    "                translation = response[0]['generated_text'].split(prompt)[-1].strip()  # extract only the new part\n",
    "\n",
    "            except Exception as e:\n",
    "                translation = f\"[ERRORE]: {e}\"\n",
    "            translations.append(translation)  # append the translation to the list\n",
    "\n",
    "        df[\"translation\"] = translations  # add the translations to the dataframe\n",
    "\n",
    "        # Crea nome file dinamico (usa solo il nome corto del modello)\n",
    "        short_model_name = model_name.split(\"/\")[-1]\n",
    "        output_file = f\"traduzioni_{short_model_name}_{prompt_name}.csv\"  # create the output file name\n",
    "\n",
    "        df.to_csv(output_file, index=False)  # save the dataframe to a csv file\n",
    "        print(f\"‚úÖ Traduzioni salvate in '{output_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
